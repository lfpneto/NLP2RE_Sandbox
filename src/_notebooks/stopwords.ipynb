{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
                        "c:\\ProgramData\\anaconda3\\python.exe\n"
                    ]
                }
            ],
            "source": [
                "# import modules\n",
                "import xml.etree.ElementTree as ET\n",
                "import pandas as pd\n",
                "import sys\n",
                "import string\n",
                "import re\n",
                "import nltk\n",
                "import sys\n",
                "import os\n",
                "import gensim\n",
                "import logging\n",
                "\n",
                "# Set up basic configuration for logging\n",
                "logging.basicConfig(\n",
                "    level=logging.ERROR,\n",
                "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
                "    handlers=[logging.StreamHandler()]  # Logs to the console\n",
                ")\n",
                "\n",
                "# Add the src directory to sys.path\n",
                "sys.path.append(os.path.abspath(r'C:\\dev\\NLP2RE_Sandbox\\src'))\n",
                "\n",
                "\n",
                "print(sys.version)\n",
                "print(sys.executable)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Specify the path to your XML file and namespace\n",
                "xml_file_path = r'C:\\dev\\NLP2RE_Sandbox\\data\\work_data\\2007-ertms.xml'\n",
                "namespace = {'ns': 'req_document.xsd'}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>tag</th>\n",
                            "      <th>text</th>\n",
                            "      <th>id</th>\n",
                            "      <th>path</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>621</th>\n",
                            "      <td>meaning</td>\n",
                            "      <td>Transmission of ETCS information from a train ...</td>\n",
                            "      <td></td>\n",
                            "      <td>req_document/p/glossary/glossary_item/meaning</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>622</th>\n",
                            "      <td>term</td>\n",
                            "      <td>Train trip</td>\n",
                            "      <td></td>\n",
                            "      <td>req_document/p/glossary/glossary_item/term</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>623</th>\n",
                            "      <td>meaning</td>\n",
                            "      <td>Is used when a train passes a \"danger\" signal,...</td>\n",
                            "      <td></td>\n",
                            "      <td>req_document/p/glossary/glossary_item/meaning</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>624</th>\n",
                            "      <td>term</td>\n",
                            "      <td>Warning</td>\n",
                            "      <td></td>\n",
                            "      <td>req_document/p/glossary/glossary_item/term</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>625</th>\n",
                            "      <td>meaning</td>\n",
                            "      <td>Audible and/or visual indication to alert the ...</td>\n",
                            "      <td></td>\n",
                            "      <td>req_document/p/glossary/glossary_item/meaning</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>626</th>\n",
                            "      <td>term</td>\n",
                            "      <td>Wheelslip</td>\n",
                            "      <td></td>\n",
                            "      <td>req_document/p/glossary/glossary_item/term</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>627</th>\n",
                            "      <td>meaning</td>\n",
                            "      <td>When a traction-driven wheel loses adhesion wi...</td>\n",
                            "      <td></td>\n",
                            "      <td>req_document/p/glossary/glossary_item/meaning</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>628</th>\n",
                            "      <td>term</td>\n",
                            "      <td>Wheelslide</td>\n",
                            "      <td></td>\n",
                            "      <td>req_document/p/glossary/glossary_item/term</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>629</th>\n",
                            "      <td>meaning</td>\n",
                            "      <td>When a braked wheel loses adhesion with the ra...</td>\n",
                            "      <td></td>\n",
                            "      <td>req_document/p/glossary/glossary_item/meaning</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>630</th>\n",
                            "      <td>title</td>\n",
                            "      <td>Other technical functions</td>\n",
                            "      <td>11</td>\n",
                            "      <td>req_document/p/title</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         tag                                               text  id  \\\n",
                            "621  meaning  Transmission of ETCS information from a train ...       \n",
                            "622     term                                         Train trip       \n",
                            "623  meaning  Is used when a train passes a \"danger\" signal,...       \n",
                            "624     term                                            Warning       \n",
                            "625  meaning  Audible and/or visual indication to alert the ...       \n",
                            "626     term                                          Wheelslip       \n",
                            "627  meaning  When a traction-driven wheel loses adhesion wi...       \n",
                            "628     term                                         Wheelslide       \n",
                            "629  meaning  When a braked wheel loses adhesion with the ra...       \n",
                            "630    title                          Other technical functions  11   \n",
                            "\n",
                            "                                              path  \n",
                            "621  req_document/p/glossary/glossary_item/meaning  \n",
                            "622     req_document/p/glossary/glossary_item/term  \n",
                            "623  req_document/p/glossary/glossary_item/meaning  \n",
                            "624     req_document/p/glossary/glossary_item/term  \n",
                            "625  req_document/p/glossary/glossary_item/meaning  \n",
                            "626     req_document/p/glossary/glossary_item/term  \n",
                            "627  req_document/p/glossary/glossary_item/meaning  \n",
                            "628     req_document/p/glossary/glossary_item/term  \n",
                            "629  req_document/p/glossary/glossary_item/meaning  \n",
                            "630                           req_document/p/title  "
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Parse .xml to df\n",
                "from utils import parse_xml\n",
                "\n",
                "# import utils.ParseXML as ParseXML\n",
                "df = parse_xml.process_xml_with_namespace(xml_file_path, namespace)\n",
                "df.tail(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'logging' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "File \u001b[1;32mC:\\dev\\NLP2RE_Sandbox\\src\\utils\\utils.py:23\u001b[0m, in \u001b[0;36mload_parameters\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Log an error message and raise an exception\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Ensure the file path is correct and the file exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'logging' is not defined",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create 'text_clean' attribute in df (list of tokens)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_data\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_clean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: clean_data\u001b[38;5;241m.\u001b[39mclean_text_original(x))\n\u001b[0;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
                        "File \u001b[1;32mC:\\dev\\NLP2RE_Sandbox\\src\\utils\\clean_data.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexpTokenizer\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stpwrds\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_parameters\n\u001b[0;32m     20\u001b[0m wn \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mWordNetLemmatizer()\n",
                        "File \u001b[1;32mC:\\dev\\NLP2RE_Sandbox\\src\\utils\\stpwrds.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_parameters\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Access the parameters\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m params \u001b[38;5;241m=\u001b[39m load_parameters(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m CUSTOM_STOPWORDS \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_preparation\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstopwords\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopword_dynamic_source\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m en_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
                        "File \u001b[1;32mC:\\dev\\NLP2RE_Sandbox\\src\\utils\\utils.py:52\u001b[0m, in \u001b[0;36mload_parameters\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Handle any other exceptions\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn unexpected error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn unexpected error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'logging' is not defined"
                    ]
                }
            ],
            "source": [
                "# Create 'text_clean' attribute in df (list of tokens)\n",
                "from utils import clean_data\n",
                "\n",
                "df['text_clean'] = df['text'].apply(lambda x: clean_data.data_preparation(x))\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'ertm': 0, 'etc': 1, 'fr': 2, 'function': 3, 'requir': 4, 'specif': 5, '00': 6, '5': 7, '06': 8, '2007': 9, '21': 10, '003204': 11, 'era': 12, 'introduct': 13, '': 14, '0': 15, '2': 16, '3': 17, 'a': 18, 'all': 19, 'and': 20, 'been': 21, 'consist': 22, 'contain': 23, 'control': 24, 'defin': 25, 'document': 26, 'european': 27, 'few': 28, 'for': 29, 'from': 30, 'have': 31, 'implement': 32, 'in': 33, 'manag': 34, 'not': 35, 'onli': 36, 'oper': 37, 'primarili': 38, 'rail': 39, 'reason': 40, 'remov': 41, 'sr': 42, 'system': 43, 'technic': 44, 'term': 45, 'the': 46, 'therefor': 47, 'thi': 48, 'traffic': 49, 'train': 50, 'version': 51, 'applic': 52, 'be': 53, 'cc': 54, 'condit': 55, 'everi': 56, 'if': 57, 'is': 58, 'it': 59, 'level': 60, 'lower': 61, 'm': 62, 'mandatori': 63, 'may': 64, 'note': 65, 'o': 66, 'of': 67, 'option': 68, 'respect': 69, 'safeti': 70, 'shall': 71, 'state': 72, 'that': 73, 'to': 74, 'tsi': 75, 'where': 76, 'gener': 77, 'basic': 78, 'allow': 79, 'drive': 80, 'driver': 81, 'him': 82, 'inform': 83, 'provid': 84, 'safe': 85, 'with': 86, 'abl': 87, 'movement': 88, 'shunt': 89, 'supervis': 90, 'area': 91, 'authoris': 92, 'by': 93, 'perform': 94, 'possibl': 95, 'prevent': 96, 'rbc': 97, 'traction': 98, 'unit': 99, '500': 100, 'h': 101, 'km': 102, 'maximum': 103, 'speed': 104, '1': 105, 'activ': 106, 'ani': 107, 'appli': 108, 'as': 109, 'avail': 110, 'balis': 111, 'can': 112, 'co': 113, 'continu': 114, 'definit': 115, 'detect': 116, 'e': 117, 'except': 118, 'fit': 119, 'follow': 120, 'g': 121, 'i': 122, 'infil': 123, 'integr': 124, 'intermitt': 125, 'limit': 126, 'loop': 127, 'media': 128, 'modul': 129, 'nation': 130, 'no': 131, 'onboard': 132, 'or': 133, 'radio': 134, 'same': 135, 'stm': 136, 'support': 137, 'track': 138, 'tracksid': 139, 'transmiss': 140, 'transmit': 141, 'via': 142, 'which': 143, 'line': 144, 'more': 145, 'on': 146, 'one': 147, 'equip': 148, 'run': 149, 'current': 150, 'dmi': 151, 'indic': 152, 'acknowledg': 153, 'after': 154, 'afterward': 155, 'brake': 156, 'doe': 157, 'releas': 158, 'request': 159, 'transit': 160, 'exist': 161, 'compat': 162, 'interf': 163, 'interfer': 164, 'list': 165, 'such': 166, 'capabl': 167, 'full': 168, 'multipl': 169, 'partial': 170, 'post': 171, 'respons': 172, 'revers': 173, 'sight': 174, 'staff': 175, 'stand': 176, 'tandem': 177, 'trainborn': 178, 'trip': 179, 'unfit': 180, 'automat': 181, 'move': 182, 'occur': 183, 'principl': 184, 'while': 185, 'appropri': 186, 'initi': 187, 'manual': 188, 'stationari': 189, 'an': 190, 'increas': 191, 'result': 192, 'seek': 193, 'whether': 194, 'case': 195, 'fail': 196, 'ha': 197, 'at': 198, 'between': 199, 'differ': 200, 'dure': 201, 'ensur': 202, 'includ': 203, 'least': 204, 'period': 205, 'protect': 206, 'restrict': 207, 'two': 208, 'accord': 209, 'given': 210, 'highest': 211, 'pass': 212, 'prioriti': 213, 'switch': 214, 'than': 215, 'statu': 216, 'valu': 217, 'adapt': 218, 'board': 219, 'receiv': 220, 'even': 221, 'off': 222, 'onc': 223, 'remain': 224, 'valid': 225, 'default': 226, 'locat': 227, 'use': 228, 'harmonis': 229, 'perman': 230, 'store': 231, 'self': 232, 'test': 233, 'start': 234, 'up': 235, 'action': 236, 'part': 237, 'data': 238, 'entri': 239, 'befor': 240, 'enter': 241, 'select': 242, 'but': 243, 'overwrit': 244, 'when': 245, 'memori': 246, 'railway': 247, 'consult': 248, 'until': 249, 'confirm': 250, 'offer': 251, 'addit': 252, 'connect': 253, 'input': 254, 'item': 255, 'other': 256, 'identif': 257, 'languag': 258, 'chang': 259, 'journey': 260, 'number': 261, 'complet': 262, 'success': 263, 'accept': 264, 'air': 265, 'axl': 266, 'calcul': 267, 'categori': 268, 'electr': 269, 'gaug': 270, 'intern': 271, 'length': 272, 'load': 273, 'power': 274, 'readi': 275, 'resolut': 276, 't': 277, 'tight': 278, 'type': 279, 'extern': 280, 'sourc': 281, 'ask': 282, 'awaken': 283, 'contact': 284, 'detail': 285, 'author': 286, 'without': 287, 's': 288, 'transfer': 289, 'obtain': 290, 'permiss': 291, 'unauthoris': 292, 'under': 293, 'base': 294, 'equal': 295, 'authomat': 296, 'permit': 297, 'danger': 298, 'show': 299, 'signal': 300, 'exit': 301, 'place': 302, 'take': 303, 'either': 304, 'second': 305, 'specifi': 306, 'within': 307, 'distanc': 308, 'ceil': 309, 'momentarili': 310, 'shown': 311, 'leav': 312, 'longer': 313, 'order': 314, 'stop': 315, 'necessari': 316, 'through': 317, 'about': 318, 'ahead': 319, 'occup': 320, 'send': 321, 'isol': 322, 'fact': 323, 'disconnect': 324, 'vehicl': 325, 'mean': 326, 'display': 327, 'against': 328, 'determin': 329, 'out': 330, 'anoth': 331, 'infrastructur': 332, 'descript': 333, 'adhes': 334, 'also': 335, 'profil': 336, 'are': 337, 'end': 338, 'reject': 339, 'relev': 340, 'curv': 341, 'most': 342, 'target': 343, 'accordingli': 344, 'certain': 345, 'expir': 346, 'section': 347, 'shorten': 348, 'time': 349, 'togeth': 350, 'could': 351, 'into': 352, 'occupi': 353, 'account': 354, 'minimum': 355, 'unless': 356, 'clear': 357, 'collect': 358, 'concern': 359, 'class': 360, 'special': 361, 'static': 362, 'basi': 363, 'dynam': 364, 'emerg': 365, 'servic': 366, 'front': 367, 'higher': 368, 'rear': 369, 'relat': 370, 'tunnel': 371, 'compli': 372, 'failur': 373, 'point': 374, 'accuraci': 375, 'deceler': 376, 'odometri': 377, 'overlap': 378, 'reach': 379, 'will': 380, 'each': 381, 'rout': 382, 'entir': 383, 'error': 384, 'actual': 385, 'discrep': 386, 'there': 387, '4': 388, '7': 389, 'enabl': 390, 'intervent': 391, 'warn': 392, 'know': 393, 'logic': 394, 'next': 395, 'understand': 396, 'way': 397, 'acoust': 398, 'avoid': 399, 'react': 400, 'visual': 401, 'non': 402, 'pre': 403, 'sent': 404, 'text': 405, 'sec': 406, 'exce': 407, 'exceed': 408, 'execut': 409, 'margin': 410, 'then': 411, 'below': 412, 'decid': 413, 'away': 414, 'roll': 415, 'direct': 416, 'monitor': 417, 'unwant': 418, 'travel': 419, 'come': 420, 'standstil': 421, 'appertain': 422, 'wa': 423, 'disabl': 424, 'lead': 425, 'record': 426, 'correct': 427, 'refer': 428, 'univers': 429, 'utc': 430, 'driven': 431, 'view': 432, 'interfac': 433, 'investig': 434, 'output': 435, 'standardis': 436, '24': 437, 'accid': 438, 'assess': 439, 'foreseen': 440, 'hour': 441, 'need': 442, 'retent': 443, 'veri': 444, 'week': 445, 'equipmen': 446, 'overrid': 447, 'reciev': 448, 'suitabl': 449, 'cab': 450, 'influenc': 451, '12': 452, '6': 453, 'id': 454, 'backward': 455, 'event': 456, 'incid': 457, 'inadvert': 458, 'suppress': 459, 'still': 460, 'intend': 461, 'command': 462, 'particular': 463, 'immedi': 464, 'alreadi': 465, 'ignor': 466, 'criteria': 467, 'meet': 468, 'unsuit': 469, 'establish': 470, 're': 471, 'trigger': 472, 'centr': 473, 'own': 474, '8': 475, 'digit': 476, 'numer': 477, 'geograph': 478, 'posit': 479, 'demand': 480, 'pantograph': 481, 'suppli': 482, 'regard': 483, 'breaker': 484, 'circuit': 485, 'close': 486, 'combin': 487, 'open': 488, 'rais': 489, 'separ': 490, 'plain': 491, 'messag': 492, 'alert': 493, 'appear': 494, 'charact': 495, 'set': 496, 'fix': 497, 'eddi': 498, 'inhibit': 499, 'magnet': 500, 'regen': 501, 'shoe': 502, 'outsid': 503, 'el': 504, 'max': 505, 'revoc': 506, 'issu': 507, 'revok': 508, 'ma': 509, 'new': 510, 'propos': 511, 'check': 512, 'cannot': 513, 'keep': 514, 'old': 515, 'procedur': 516, 'extend': 517, 'cancel': 518, 'handov': 519, 'penalti': 520, 'space': 521, 'might': 522, 'back': 523, 'fall': 524, 'interrupt': 525, 'loss': 526, 'proceed': 527, 'reaction': 528, 'unrestrict': 529, 'bring': 530, 'compromis': 531, 'occurr': 532, 'fault': 533, 'machin': 534, 'mainten': 535, 'ram': 536, 'reliabl': 537, 'environment': 538, 'glossari': 539, 'describ': 540, 'normal': 541, 'pleas': 542, 'titl': 543, 'absolut': 544, 'greater': 545, 'situat': 546, 'advisori': 547, 'assist': 548, 'counter': 549, 'count': 550, 'extrem': 551, 'he': 552, 'method': 553, 'mount': 554, 'devic': 555, 'bank': 556, 'coupl': 557, 'hill': 558, 'top': 559, 'whilst': 560, 'block': 561, 'divid': 562, 'paramet': 563, 'approv': 564, 'taken': 565, 'dedic': 566, 'identifi': 567, 'long': 568, 'uniqu': 569, 'ct': 570, 'central': 571, 'hi': 572, 'obstacl': 573, 'violat': 574, 'characterist': 575, 'depend': 576, '03': 577, '541': 578, 'leaflet': 579, 'uic': 580, 'zero': 581, 'instal': 582, 'main': 583, 'station': 584, 'advanc': 585, 'b': 586, 'said': 587, 'would': 588, 'abil': 589, 'exampl': 590, 'interlock': 591, 'medium': 592, 'short': 593, 'cut': 594, 'local': 595, 'offset': 596, 'aspect': 597, 'some': 598, 'constraint': 599, 'adjust': 600, 'mechan': 601, 'pneumat': 602, 'administr': 603, 'regul': 604, 'rule': 605, 'measur': 606, 'entranc': 607, 'lock': 608, 'must': 609, 'overhead': 610, 'wire': 611, 'signalman': 612, 'propel': 613, 'forward': 614, 'itself': 615, 'master': 616, 'see': 617, 'trainset': 618, 'purpos': 619, 'scope': 620, 'well': 621, 'channel': 622, 'commun': 623, 'spoken': 624, 'updat': 625, 'rel': 626, 'less': 627, 'approach': 628, 'both': 629, 'locomot': 630, 'prepar': 631, 'map': 632, 'first': 633, 'haul': 634, 'br': 635, 'face': 636, 'ident': 637, 'make': 638, 'trail': 639, 'necessarili': 640, 'ssr': 641, 'sub': 642, 'expect': 643, 'temporari': 644, 'behalf': 645, 'plan': 646, 'free': 647, 'replac': 648, 'tradit': 649, 'becaus': 650, 'construct': 651, 'characteris': 652, 'countri': 653, 'tabl': 654, 'similar': 655, 'caus': 656, 'exclud': 657, 'facil': 658, 'occas': 659, 'audibl': 660, 'wheelslip': 661, 'lose': 662, 'wheel': 663, 'wheelslid': 664}\n"
                    ]
                }
            ],
            "source": [
                " # Create a Dictionary: Associate each word in the corpus with a unique integer ID\n",
                "\n",
                "from gensim import corpora\n",
                "\n",
                "dct = corpora.Dictionary(df['text_clean'])\n",
                "print(dct.token2id)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[('the', 548), ('train', 250), ('', 231), ('to', 214), ('shall', 210), ('be', 189), ('a', 157), ('of', 149), ('etc', 104), ('and', 97)]\n"
                    ]
                }
            ],
            "source": [
                "# Return a list of the n most common words and their counts from the most common to the least.\n",
                "print(dct.most_common(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Corner cases:\n",
                "joint → _joint \n",
                "jointed → _joint, ed \n",
                "disjointed → _di, s, jo, int, ed \n",
                "unisex → _un, ise, x \n",
                "true → _true \n",
                "untrue → _un, tr, ue \n",
                "estimate → _estimate \n",
                "overestimate → _over, est, imate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Syntax\n",
                "Below is the syntax for the gensim.utils.tokenize() function:\n",
                "\n",
                "```python\n",
                "gensim.utils.tokenize(text, lowercase=True, deacc=False, errors='strict', to_lower=False, lower=False)\n",
                "```\n",
                "\n",
                "text is the input text to be tokenized.\n",
                "\n",
                "lowercase is an optional parameter that specifies whether to convert the text to lowercase before tokenization. The default value is True.\n",
                "\n",
                "deacc is an optional parameter specifying whether to remove text accent marks. The default value is False.\n",
                "\n",
                "errors is an optional parameter that specifies how to handle decoding errors in the text. The default value is 'strict'.\n",
                "\n",
                "to_lower and lower are both optional parameters that are the same as lowercase and are used as a convenient alias."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['welcome', 'to', 'educative', 'answers', 'joint', 'jointed', 'disjointed', 'unisex', 'true', 'untrue', 'estimate', 'overestimate']\n"
                    ]
                }
            ],
            "source": [
                "from gensim.utils import tokenize\n",
                "\n",
                "text = \"\"\" Welcome to Educative Answers.\n",
                "        joint\n",
                "        jointed \n",
                "        disjointed \n",
                "        unisex \n",
                "        true \n",
                "        untrue \n",
                "        estimate \n",
                "        overestimate \n",
                "        \"\"\"\n",
                "\n",
                "tokens = list(tokenize(text,lowercase=True))\n",
                "print(tokens)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk\n",
                "from nltk.corpus import stopwords\n",
                "en_stop = set(stopwords.words('english'))\n",
                "stopped_tokens = [word for word in tokens if word not in en_stop]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Remove costum stopwords from a dictionary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'ten', '', 'nevertheless', 'get', 'toward', 'therein', 'did', 'call', 'became', 'doesn', 'latter', 'can', 'up', 'co', 'seems', 'interest', 'along', 'mill', 'if', 'our', 'you', 'my', 'which', 'where', 'thick', 'whom', 'whereupon', 'well', 'neither', 'would', 'whereafter', 'herself', 'former', 'same', 'do', 'should', 'too', 'sometime', 'further', 'whereas', 'moreover', 'un', 'noone', 'via', 'elsewhere', 'whence', 'except', 'give', 'me', 'almost', 'twelve', 'yours', 'being', 'ever', 'formerly', 'afterwards', 'something', 'or', 'their', 'above', 'always', 'full', 'nothing', 'is', 'hence', 'side', 'upon', 'ours', 'the', 'beyond', 'beside', 'not', 'those', 'three', 'etc', 'must', 'part', 'had', 'an', 'may', 'as', 'back', 'after', 'each', 'wherein', 'thru', 'at', 'does', 'off', 'someone', 'however', 'beforehand', 'couldnt', 'that', 'least', 'see', 'hundred', 'eleven', 'itself', 'front', 'than', 'really', 'it', 'fr', 'most', 'was', 'between', 'why', 'on', 'although', 'into', 'empty', 'towards', 'we', 'made', 'none', 'could', 'indeed', 'become', 'ertm', 'whenever', 'there', 'fifteen', 'nobody', 'over', 'they', 'top', 'fifty', 'per', 'found', 'hers', 'here', 'its', 'again', 'show', 'serious', 'yourself', 'are', 'put', 'name', 'twenty', 'am', 'last', 'cant', 'amoungst', 'might', 'against', 'below', 'herein', 'fire', 'thence', 'anyone', 'otherwise', 'ourselves', 'out', 'nor', 'across', 'becomes', 'though', 'some', 'cannot', 'seeming', 'throughout', 'even', 'them', 'while', 'everywhere', 'six', 'own', 'fill', 'using', 'to', 'only', 'every', 'within', 'once', 'becoming', 'these', 'about', 'many', 'several', 'sometimes', 'still', 'more', 'quite', 'done', 'namely', 'whoever', 'doing', 'therefore', 'meanwhile', 'didn', 'yet', 'keep', 'move', 'were', 'so', 'everyone', 'due', 'behind', 'and', 'hasnt', 'another', 'eight', 'who', 'cry', 'wherever', 'of', 'amount', 'have', 'but', 'no', 'take', 'what', 'shall', 'yourselves', 'everything', 'either', 'detail', 'besides', 'just', 'thin', 'go', 'hereupon', 'third', 'nine', 'hereby', 'in', 'amongst', 'from', 'during', 'unless', 'whatever', 'without', 'alone', 'next', 'thereupon', 'never', 'first', 'computer', 'now', 'don', 'very', 'together', 'one', 'under', 'regarding', 'seemed', 'will', 'sincere', 'enough', 'latterly', 'say', 'somewhere', 'when', 'he', 'bottom', 'themselves', 'de', 'system', 'various', 'whole', 'bill', 'your', 'also', 'whether', 'all', 'please', 'sixty', 'four', 'often', 'whither', 'two', 'describe', 'whereby', 'her', 'con', 'us', 'until', 'any', 'mostly', 'his', 'thus', 'mine', 'a', 'seem', 're', 'forty', 'whose', 'less', 'eg', 'then', 'few', 'ie', 'ltd', 'himself', 'since', 'down', 'she', 'hereafter', 'him', 'thereafter', 'five', 'been', 'be', 'make', 'this', 'rather', 'both', 'through', 'nowhere', 'other', 'i', 'thereby', 'others', 'anyhow', 'myself', 'anyway', 'km', 'how', 'find', 'else', 'around', 'because', 'somehow', 'with', 'used', 'onto', 'already', 'anything', 'among', 'for', 'inc', 'kg', 'perhaps', 'has', 'by', 'much', 'anywhere', 'before', 'such'}\n"
                    ]
                }
            ],
            "source": [
                "# Initialize \"stopword\" list\n",
                "from gensim.parsing.preprocessing import STOPWORDS\n",
                "\n",
                "stopwords = set(STOPWORDS)\n",
                "stopwords.add(\"ertm\")\n",
                "stopwords.add(\"fr\")\n",
                "stopwords.add(\"shall\")\n",
                "stopwords.add(\"\")\n",
                "\n",
                "print(stopwords)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'function': 0, 'requir': 1, 'specif': 2, '00': 3, '5': 4, '06': 5, '2007': 6, '21': 7, '003204': 8, 'era': 9, 'introduct': 10, '0': 11, '2': 12, '3': 13, 'consist': 14, 'contain': 15, 'control': 16, 'defin': 17, 'document': 18, 'european': 19, 'implement': 20, 'manag': 21, 'onli': 22, 'oper': 23, 'primarili': 24, 'rail': 25, 'reason': 26, 'remov': 27, 'sr': 28, 'technic': 29, 'term': 30, 'therefor': 31, 'thi': 32, 'traffic': 33, 'train': 34, 'version': 35, 'applic': 36, 'cc': 37, 'condit': 38, 'everi': 39, 'level': 40, 'lower': 41, 'm': 42, 'mandatori': 43, 'note': 44, 'o': 45, 'option': 46, 'respect': 47, 'safeti': 48, 'state': 49, 'tsi': 50, 'gener': 51, 'basic': 52, 'allow': 53, 'drive': 54, 'driver': 55, 'inform': 56, 'provid': 57, 'safe': 58, 'abl': 59, 'movement': 60, 'shunt': 61, 'supervis': 62, 'area': 63, 'authoris': 64, 'perform': 65, 'possibl': 66, 'prevent': 67, 'rbc': 68, 'traction': 69, 'unit': 70, '500': 71, 'h': 72, 'maximum': 73, 'speed': 74, '1': 75, 'activ': 76, 'ani': 77, 'appli': 78, 'avail': 79, 'balis': 80, 'continu': 81, 'definit': 82, 'detect': 83, 'e': 84, 'fit': 85, 'follow': 86, 'g': 87, 'infil': 88, 'integr': 89, 'intermitt': 90, 'limit': 91, 'loop': 92, 'media': 93, 'modul': 94, 'nation': 95, 'onboard': 96, 'radio': 97, 'stm': 98, 'support': 99, 'track': 100, 'tracksid': 101, 'transmiss': 102, 'transmit': 103, 'line': 104, 'equip': 105, 'run': 106, 'current': 107, 'dmi': 108, 'indic': 109, 'acknowledg': 110, 'afterward': 111, 'brake': 112, 'doe': 113, 'releas': 114, 'request': 115, 'transit': 116, 'exist': 117, 'compat': 118, 'interf': 119, 'interfer': 120, 'list': 121, 'capabl': 122, 'multipl': 123, 'partial': 124, 'post': 125, 'respons': 126, 'revers': 127, 'sight': 128, 'staff': 129, 'stand': 130, 'tandem': 131, 'trainborn': 132, 'trip': 133, 'unfit': 134, 'automat': 135, 'occur': 136, 'principl': 137, 'appropri': 138, 'initi': 139, 'manual': 140, 'stationari': 141, 'increas': 142, 'result': 143, 'seek': 144, 'case': 145, 'fail': 146, 'ha': 147, 'differ': 148, 'dure': 149, 'ensur': 150, 'includ': 151, 'period': 152, 'protect': 153, 'restrict': 154, 'accord': 155, 'given': 156, 'highest': 157, 'pass': 158, 'prioriti': 159, 'switch': 160, 'statu': 161, 'valu': 162, 'adapt': 163, 'board': 164, 'receiv': 165, 'onc': 166, 'remain': 167, 'valid': 168, 'default': 169, 'locat': 170, 'use': 171, 'harmonis': 172, 'perman': 173, 'store': 174, 'self': 175, 'test': 176, 'start': 177, 'action': 178, 'data': 179, 'entri': 180, 'befor': 181, 'enter': 182, 'select': 183, 'overwrit': 184, 'memori': 185, 'railway': 186, 'consult': 187, 'confirm': 188, 'offer': 189, 'addit': 190, 'connect': 191, 'input': 192, 'item': 193, 'identif': 194, 'languag': 195, 'chang': 196, 'journey': 197, 'number': 198, 'complet': 199, 'success': 200, 'accept': 201, 'air': 202, 'axl': 203, 'calcul': 204, 'categori': 205, 'electr': 206, 'gaug': 207, 'intern': 208, 'length': 209, 'load': 210, 'power': 211, 'readi': 212, 'resolut': 213, 't': 214, 'tight': 215, 'type': 216, 'extern': 217, 'sourc': 218, 'ask': 219, 'awaken': 220, 'contact': 221, 'author': 222, 's': 223, 'transfer': 224, 'obtain': 225, 'permiss': 226, 'unauthoris': 227, 'base': 228, 'equal': 229, 'authomat': 230, 'permit': 231, 'danger': 232, 'signal': 233, 'exit': 234, 'place': 235, 'second': 236, 'specifi': 237, 'distanc': 238, 'ceil': 239, 'momentarili': 240, 'shown': 241, 'leav': 242, 'longer': 243, 'order': 244, 'stop': 245, 'necessari': 246, 'ahead': 247, 'occup': 248, 'send': 249, 'isol': 250, 'fact': 251, 'disconnect': 252, 'vehicl': 253, 'mean': 254, 'display': 255, 'determin': 256, 'anoth': 257, 'infrastructur': 258, 'descript': 259, 'adhes': 260, 'profil': 261, 'end': 262, 'reject': 263, 'relev': 264, 'curv': 265, 'target': 266, 'accordingli': 267, 'certain': 268, 'expir': 269, 'section': 270, 'shorten': 271, 'time': 272, 'togeth': 273, 'occupi': 274, 'account': 275, 'minimum': 276, 'clear': 277, 'collect': 278, 'concern': 279, 'class': 280, 'special': 281, 'static': 282, 'basi': 283, 'dynam': 284, 'emerg': 285, 'servic': 286, 'higher': 287, 'rear': 288, 'relat': 289, 'tunnel': 290, 'compli': 291, 'failur': 292, 'point': 293, 'accuraci': 294, 'deceler': 295, 'odometri': 296, 'overlap': 297, 'reach': 298, 'rout': 299, 'entir': 300, 'error': 301, 'actual': 302, 'discrep': 303, '4': 304, '7': 305, 'enabl': 306, 'intervent': 307, 'warn': 308, 'know': 309, 'logic': 310, 'understand': 311, 'way': 312, 'acoust': 313, 'avoid': 314, 'react': 315, 'visual': 316, 'non': 317, 'pre': 318, 'sent': 319, 'text': 320, 'sec': 321, 'exce': 322, 'exceed': 323, 'execut': 324, 'margin': 325, 'decid': 326, 'away': 327, 'roll': 328, 'direct': 329, 'monitor': 330, 'unwant': 331, 'travel': 332, 'come': 333, 'standstil': 334, 'appertain': 335, 'wa': 336, 'disabl': 337, 'lead': 338, 'record': 339, 'correct': 340, 'refer': 341, 'univers': 342, 'utc': 343, 'driven': 344, 'view': 345, 'interfac': 346, 'investig': 347, 'output': 348, 'standardis': 349, '24': 350, 'accid': 351, 'assess': 352, 'foreseen': 353, 'hour': 354, 'need': 355, 'retent': 356, 'veri': 357, 'week': 358, 'equipmen': 359, 'overrid': 360, 'reciev': 361, 'suitabl': 362, 'cab': 363, 'influenc': 364, '12': 365, '6': 366, 'id': 367, 'backward': 368, 'event': 369, 'incid': 370, 'inadvert': 371, 'suppress': 372, 'intend': 373, 'command': 374, 'particular': 375, 'immedi': 376, 'alreadi': 377, 'ignor': 378, 'criteria': 379, 'meet': 380, 'unsuit': 381, 'establish': 382, 'trigger': 383, 'centr': 384, '8': 385, 'digit': 386, 'numer': 387, 'geograph': 388, 'posit': 389, 'demand': 390, 'pantograph': 391, 'suppli': 392, 'regard': 393, 'breaker': 394, 'circuit': 395, 'close': 396, 'combin': 397, 'open': 398, 'rais': 399, 'separ': 400, 'plain': 401, 'messag': 402, 'alert': 403, 'appear': 404, 'charact': 405, 'set': 406, 'fix': 407, 'eddi': 408, 'inhibit': 409, 'magnet': 410, 'regen': 411, 'shoe': 412, 'outsid': 413, 'el': 414, 'max': 415, 'revoc': 416, 'issu': 417, 'revok': 418, 'ma': 419, 'new': 420, 'propos': 421, 'check': 422, 'old': 423, 'procedur': 424, 'extend': 425, 'cancel': 426, 'handov': 427, 'penalti': 428, 'space': 429, 'fall': 430, 'interrupt': 431, 'loss': 432, 'proceed': 433, 'reaction': 434, 'unrestrict': 435, 'bring': 436, 'compromis': 437, 'occurr': 438, 'fault': 439, 'machin': 440, 'mainten': 441, 'ram': 442, 'reliabl': 443, 'environment': 444, 'glossari': 445, 'describ': 446, 'normal': 447, 'pleas': 448, 'titl': 449, 'absolut': 450, 'greater': 451, 'situat': 452, 'advisori': 453, 'assist': 454, 'counter': 455, 'count': 456, 'extrem': 457, 'method': 458, 'mount': 459, 'devic': 460, 'bank': 461, 'coupl': 462, 'hill': 463, 'whilst': 464, 'block': 465, 'divid': 466, 'paramet': 467, 'approv': 468, 'taken': 469, 'dedic': 470, 'identifi': 471, 'long': 472, 'uniqu': 473, 'ct': 474, 'central': 475, 'hi': 476, 'obstacl': 477, 'violat': 478, 'characterist': 479, 'depend': 480, '03': 481, '541': 482, 'leaflet': 483, 'uic': 484, 'zero': 485, 'instal': 486, 'main': 487, 'station': 488, 'advanc': 489, 'b': 490, 'said': 491, 'abil': 492, 'exampl': 493, 'interlock': 494, 'medium': 495, 'short': 496, 'cut': 497, 'local': 498, 'offset': 499, 'aspect': 500, 'constraint': 501, 'adjust': 502, 'mechan': 503, 'pneumat': 504, 'administr': 505, 'regul': 506, 'rule': 507, 'measur': 508, 'entranc': 509, 'lock': 510, 'overhead': 511, 'wire': 512, 'signalman': 513, 'propel': 514, 'forward': 515, 'master': 516, 'trainset': 517, 'purpos': 518, 'scope': 519, 'channel': 520, 'commun': 521, 'spoken': 522, 'updat': 523, 'rel': 524, 'approach': 525, 'locomot': 526, 'prepar': 527, 'map': 528, 'haul': 529, 'br': 530, 'face': 531, 'ident': 532, 'trail': 533, 'necessarili': 534, 'ssr': 535, 'sub': 536, 'expect': 537, 'temporari': 538, 'behalf': 539, 'plan': 540, 'free': 541, 'replac': 542, 'tradit': 543, 'becaus': 544, 'construct': 545, 'characteris': 546, 'countri': 547, 'tabl': 548, 'similar': 549, 'caus': 550, 'exclud': 551, 'facil': 552, 'occas': 553, 'audibl': 554, 'wheelslip': 555, 'lose': 556, 'wheel': 557, 'wheelslid': 558}\n"
                    ]
                }
            ],
            "source": [
                "# Remove the words from the dictionary\n",
                "\n",
                "# Get the ids of the words to be removed\n",
                "ids_to_remove = [dct.token2id[word] for word in stopwords if word in dct.token2id]\n",
                "\n",
                "# Filter the dictionary\n",
                "dct.filter_tokens(bad_ids=ids_to_remove)\n",
                "\n",
                "# Compact the dictionary to remove gaps in the id sequence\n",
                "dct.compactify()\n",
                "\n",
                "# Print the remaining words in the dictionary\n",
                "print(dct.token2id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of unique tokens: 559\n",
                        "[('train', 250), ('driver', 90), ('speed', 78), ('oper', 64), ('equip', 60), ('data', 60), ('inform', 53), ('movement', 53), ('brake', 52), ('supervis', 51)]\n"
                    ]
                }
            ],
            "source": [
                "# Return a list of the n most common words and their counts from the most common to the least.\n",
                "dct.compactify()\n",
                "print(\"Number of unique tokens:\", len(dct))\n",
                "print(dct.most_common(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of unique tokens: 547\n",
                        "[('function', 37), ('nation', 33), ('requir', 32), ('shunt', 32), ('level', 30), ('dmi', 30), ('trainborn', 30), ('tracksid', 29), ('transmiss', 29), ('valu', 29)]\n"
                    ]
                }
            ],
            "source": [
                "dct.filter_extremes(no_below=0, no_above=0.075, keep_n=1000000)\n",
                "# Return a list of the n most common words and their counts from the most common to the least.\n",
                "dct.compactify()\n",
                "print(\"Number of unique tokens:\", len(dct))\n",
                "print(dct.most_common(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from utils import stpwrds\n",
                "\n",
                "# Define some new stopwords to add\n",
                "new_stopwords = ['example', 'string', 'some', 'stopwords']\n",
                "\n",
                "# Add the new stopwords to the JSON file\n",
                "stpwrds.add_custom_stopwords_to_json(new_stopwords)\n",
                "\n",
                "# Define an input string to clean\n",
                "input_string = \"This is an example of a string with some stopwords that need to be removed.\"\n",
                "\n",
                "# Remove stopwords from the input string\n",
                "cleaned_string = stpwrds.remove_custom_stopwords_from_string(input_string)\n",
                "\n",
                "print(\"Original String:\")\n",
                "print(input_string)\n",
                "print(\"\\nCleaned String:\")\n",
                "print(cleaned_string)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
